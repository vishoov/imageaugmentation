{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishoov/imageaugmentation/blob/main/Vishoo_Verma_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCrtSvz6hGYk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf ### models\n",
        "import numpy as np ### math computations\n",
        "import matplotlib.pyplot as plt ### plotting bar chart\n",
        "import sklearn ### machine learning library\n",
        "import cv2 ## image processing\n",
        "import datetime\n",
        "import random\n",
        "import albumentations as A\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Input, Dropout, RandomFlip, RandomRotation, Resizing, Rescaling\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy, FalsePositives, FalseNegatives, TruePositives, TrueNegatives, Precision, Recall, AUC, binary_accuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers  import L2, L1\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "-m-u6Uqqfzwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "for i in range(9):  \n",
        "  pyplot.subplot(330 + 1 + i)\n",
        "  pyplot.imshow(x_train[i+100], cmap=pyplot.get_cmap('gray'))\n",
        "  pyplot.show()\n",
        " \n",
        "  print(x_train.shape)"
      ],
      "metadata": {
        "id": "iEyhVZes4Wg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_mask(image, size=12, n_squares=1):\n",
        "    h, w, channels = image.shape\n",
        "    new_image = image\n",
        "    for _ in range(n_squares):\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "        y1 = np.clip(y - size // 2, 0, h)\n",
        "        y2 = np.clip(y + size // 2, 0, h)\n",
        "        x1 = np.clip(x - size // 2, 0, w)\n",
        "        x2 = np.clip(x + size // 2, 0, w)\n",
        "        new_image[y1:y2,x1:x2,:] = 0\n",
        "    return new_image"
      ],
      "metadata": {
        "id": "eMXd0Se7EC-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3wK6c5Axw-Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def box(lamda):\n",
        "  \n",
        "  r_x = tf.cast(tfp.distributions.Uniform(0, IM_SIZE).sample(1)[0], dtype = tf.int32)\n",
        "  r_y = tf.cast(tfp.distributions.Uniform(0, IM_SIZE).sample(1)[0], dtype = tf.int32)\n",
        "\n",
        "  r_w = tf.cast(IM_SIZE*tf.math.sqrt(1-lamda), dtype = tf.int32)\n",
        "  r_h = tf.cast(IM_SIZE*tf.math.sqrt(1-lamda), dtype = tf.int32)\n",
        "\n",
        "  r_x = tf.clip_by_value(r_x - r_w//2, 0, IM_SIZE)\n",
        "  r_y = tf.clip_by_value(r_y - r_h//2, 0, IM_SIZE)\n",
        "\n",
        "  x_b_r = tf.clip_by_value(r_x + r_w//2, 0, IM_SIZE)\n",
        "  y_b_r = tf.clip_by_value(r_y + r_h//2, 0, IM_SIZE)\n",
        "\n",
        "  r_w = x_b_r - r_x\n",
        "  if(r_w == 0):\n",
        "    r_w  = 1\n",
        "\n",
        "  r_h = y_b_r - r_y\n",
        "  if(r_h == 0):\n",
        "    r_h = 1\n",
        "\n",
        "  return r_y, r_x, r_h, r_w"
      ],
      "metadata": {
        "id": "p7GFBvcZxzQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cutmix(x_train, y_train):\n",
        "  (image_1,label_1), (image_2, label_2) = x_train, y_train\n",
        "\n",
        "  lamda = tfp.distributions.Beta(0.2,0.2)\n",
        "  lamda = lamda.sample(1)[0]\n",
        "  \n",
        "  r_y, r_x, r_h, r_w = box(lamda)\n",
        "  crop_2 = tf.image.crop_to_bounding_box(image_2, r_y, r_x, r_h, r_w)\n",
        "  pad_2 = tf.image.pad_to_bounding_box(crop_2, r_y, r_x, IM_SIZE, IM_SIZE)\n",
        "\n",
        "  crop_1 = tf.image.crop_to_bounding_box(image_1, r_y, r_x, r_h, r_w)\n",
        "  pad_1 = tf.image.pad_to_bounding_box(crop_1, r_y, r_x, IM_SIZE, IM_SIZE)\n",
        "\n",
        "  image = image_1 - pad_1 + pad_2\n",
        "\n",
        "  lamda = tf.cast(1- (r_w*r_h)/(IM_SIZE*IM_SIZE), dtype = tf.float32)\n",
        "  label = lamda*tf.cast(label_1, dtype = tf.float32) + (1-lamda)*tf.cast(label_2, dtype = tf.float32)\n",
        "\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "aHA9OGXwx59h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(x_train.shape[1], x_train.shape[2], 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "9QqTAS2C2s92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Onr0DO0fLSSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WFnpfzuYGpFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_train, y_train), epochs=7, batch_size=10, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "XMpsPXc4H_uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Metrics(Test loss & Test Accuracy): \")\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "xIo3AphU-QKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}